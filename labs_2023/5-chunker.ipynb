{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23cd4b76c10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    \"\"\"\n",
    "    Return the top `count` closest words to the target word\n",
    "    :param target_word: the target word\n",
    "    :param embeddings: a dictionary of word embeddings\n",
    "    :param count: the number of closest words to return\n",
    "    :return: a list of the `count` closest words to the target word\n",
    "    \"\"\"\n",
    "    # Get the embedding for the target word\n",
    "    target_embedding = embeddings[target_word]\n",
    "    \n",
    "    # Compute the cosine similarity between the target embedding and all other embeddings\n",
    "    similarities = cosine_similarity(target_embedding.reshape(1, -1), list(embeddings.values()))\n",
    "    \n",
    "    # Get the indices of the `count` most similar embeddings\n",
    "    closest_indices = np.argsort(similarities)[0][-count:]\n",
    "    \n",
    "    # Get the words corresponding to the closest embeddings\n",
    "    closest_words = [list(embeddings.keys())[i] for i in reversed(closest_indices)]\n",
    "    \n",
    "    return closest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        x = [word[key_x] if not tolower else word[key_x].lower() for word in sentence]\n",
    "        y = [word[key_y] for word in sentence]\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "from collections import Counter\n",
    "\n",
    "# Extract the list of unique words and chunk tags from the training set\n",
    "word_counts = Counter()\n",
    "chunk_counts = Counter()\n",
    "for sentence in train_dict:\n",
    "    for word in sentence:\n",
    "        word_counts[word['form'].lower()] += 1\n",
    "        chunk_counts[word['chunk']] += 1\n",
    "words = sorted(list(set(word_counts.keys())))\n",
    "chunks = sorted(list(set(chunk_counts.keys())))\n",
    "\n",
    "# Print the number of unique words\n",
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(list(set(embedded_words + words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code:\n",
    "idx2word = {idx:word for idx,word in enumerate(vocabulary_words, 2)}\n",
    "idx2chunk = {idx:chunk for idx,chunk in enumerate(chunks, 1)}\n",
    "word2idx = {word:idx for idx,word in enumerate(vocabulary_words, 2)}\n",
    "chunk2idx = {chunk:idx for idx,chunk in enumerate(chunks, 1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        ind = word2idx[word]\n",
    "        embedding_matrix[ind] = embeddings_dict[word]\n",
    "    else:\n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    x_w = []\n",
    "    for w in x:\n",
    "        x_w.append(word2idx.get(w))\n",
    "    X_train_idx.append(x_w)\n",
    "\n",
    "    y_w = []\n",
    "  \n",
    "    for ww in y:\n",
    "        y_w.append(chunk2idx.get(ww))\n",
    "    Y_train_idx.append(y_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx,True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix),padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_units, bidirectional=bidi_lstm, batch_first=True)\n",
    "        self.fc = nn.Linear(lstm_units * (2 if bidi_lstm else 1), nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embedded = self.embedding(sentence)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        logits = self.fc(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:18<00:00, 15.54it/s]\n",
      "100%|██████████| 280/280 [00:18<00:00, 15.17it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.92it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 16.27it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.98it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 16.09it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.96it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 16.14it/s]\n",
      "100%|██████████| 280/280 [00:18<00:00, 15.10it/s]\n",
      "100%|██████████| 280/280 [00:18<00:00, 15.38it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.76it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.83it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.89it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 15.90it/s]\n",
      "100%|██████████| 280/280 [00:17<00:00, 16.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'united', 'states', 'might', 'collapsez', '.']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[358640, 373606, 343335, 245002, 1, 873]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code get(x) or 1 for x in sentence\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = [word2idx.get(x) or 1 for x in sentence]\n",
    "sentence_word_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "model1.eval()\n",
    "sent_chunk_predictions = model1(torch.tensor(sentence_word_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8094e-08, 4.2854e-06, 1.0940e-05, 1.7341e-07, 5.0288e-07, 1.9194e-06,\n",
       "        9.9981e-01, 1.9927e-05, 2.2163e-06, 5.1994e-07, 1.3551e-07, 6.8459e-09,\n",
       "        8.1910e-08, 3.1639e-08, 1.2788e-07, 9.9923e-08, 1.9065e-05, 1.0744e-07,\n",
       "        1.0830e-07, 1.5934e-08, 1.4901e-07, 2.1922e-09, 1.3147e-04],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "test_answers = [[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
    "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
    "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
    "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
    "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
    "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
    "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
    "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
    "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
    "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
    "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
    "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
    "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
    "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
    "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
    "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
    "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]\n",
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]\n",
    "print(test_dict[1:2] == test_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    x_list =[]\n",
    "    for w in x:\n",
    "        x_list.append(word2idx.get(w) or 1)\n",
    "\n",
    "    X_test_idx.append(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hampu\\AppData\\Local\\Temp\\ipykernel_20468\\3652702108.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_test_hat_probs = model1(torch.tensor(X_test_padded))\n"
     ]
    }
   ],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(torch.tensor(X_test_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-1.6299, -0.0408, -1.3849,  ..., -1.1575, -0.3174,  2.9420],\n",
      "        [-2.5803, -1.5821,  0.1364,  ..., -1.9108,  3.1033,  4.6533],\n",
      "        [-3.9117,  1.6018,  2.3912,  ..., -2.7060, -2.7708,  4.5568],\n",
      "        ...,\n",
      "        [11.0242, -4.2097, -4.2228,  ..., -3.2062, -6.2903, -0.8902],\n",
      "        [10.2288, -3.7063, -3.9687,  ..., -2.9560, -6.0911, -0.9398],\n",
      "        [ 9.6047, -3.3009, -3.6788,  ..., -2.7657, -5.9660, -0.9512]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-SBAR'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "their_test_dict = [{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
    " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
    " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
    " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
    " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
    " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'},\n",
    " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
    " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
    " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
    " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
    " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
    " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
    " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
    " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
    " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
    " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
    " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]\n",
    "test_dict[1] == their_test_dict\n",
    "test_dict[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9060849598163031"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e2d8514a64d6c911a86c8209c193e3bd34e7280c36829bb9064dbe0ec006da3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
